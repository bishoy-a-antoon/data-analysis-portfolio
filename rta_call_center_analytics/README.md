
## Project Structure
```shell
rta_call_center_analytics/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/        # Raw/generated CSV data files
â”‚   â”œâ”€â”€ processed/  # Cleaned and feature-engineered data files
â”‚   â””â”€â”€ scripts/    # Scripts that generate or update data (e.g. data_generation.py)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_data_generation.ipynb    # Explore and build data generation logic (shifts, breaks, agents)
â”‚   â”œâ”€â”€ 02_data_cleaning.ipynb      # Data cleaning and feature engineering
â”‚   â”œâ”€â”€ 03_eda.ipynb                # Exploratory analysis
â”‚   â””â”€â”€ 04_static_report.ipynb      # Full narrative report with visualizations & summary stats
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py              # Streamlit app entrypoint (interactive dashboard)
â”‚   â”œâ”€â”€ metrics.py          # Key metrics calculation functions
â”‚   â”œâ”€â”€ data_processing.py  # Data loading, caching, and preprocessing functions
â”‚   â”œâ”€â”€ visuals.py          # Plotly figures and visualization helpers
â”‚   â””â”€â”€ config.py           # Config/constants for the app (e.g. paths, thresholds)
â”‚
â”œâ”€â”€ requirements.txt    # Python dependencies (pandas, plotly, streamlit, etc)
â”œâ”€â”€ README.md           # Project overview, how to run notebooks & app, etc.
â””â”€â”€ .gitignore          # Ignore data files, pycache, env, etc
```

## SLAs
### Examples:
- Service level %: Percent of calls answered within X seconds (e.g., 80% within 20 seconds)
- Average speed of answer (ASA): Average wait time before call is answered
- Abandonment rate: % calls dropped or abandoned before answer
- First call resolution rate

### Resources:
- [Erlang C formula](https://en.wikipedia.org/wiki/Erlang_(unit)#Erlang_C_formula)
- [Queueing theory](https://en.wikipedia.org/wiki/Queueing_theory)





Got it âœ…
Hereâ€™s a **clean Markdown doc** that summarizes everything weâ€™ve discussed about your RTA portfolio project setup, tools, and reasoning. You can drop this into a `README.md` in your project repo.

---

# ğŸ“Š RTA Portfolio Project â€” Documentation & Reasoning

This document outlines the design decisions, workflow, and technical setup for the **Real-Time Analytics (RTA) Portfolio Project**. The goal is to build a project that both **demonstrates analytical skills** and **stands out to recruiters** for junior RTA or BI analyst roles.

---

## ğŸ¯ Project Goals

* Build a realistic **real-time analytics simulation** (calls, agents, shifts, SLAs).
* Show **practical BI/analytics workflow**: data â†’ cleaning â†’ analysis â†’ dashboards â†’ reporting.
* Keep the setup **minimal but professional**, balancing recruiter accessibility and technical credibility.
* Make outputs **shareable** (static reports) and **interactive** (dashboards/notebooks).

---

## ğŸ“‚ Project Structure

```
rta-portfolio/
â”‚
â”œâ”€â”€ config/                   # Shared imports, constants, settings
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ imports.py            # All Python imports
â”‚   â””â”€â”€ constants.py          # Business constants (SLA, shift rules, etc.)
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebooks (analysis, dashboards)
â”‚   â”œâ”€â”€ 01_data_generation.ipynb
â”‚   â”œâ”€â”€ 02_analysis.ipynb
â”‚   â””â”€â”€ 03_reporting.ipynb
â”‚
â”œâ”€â”€ scripts/                  # Python scripts (reusable logic)
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ data/                     # Input/output datasets
â”‚   â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ exports/
â”‚
â”œâ”€â”€ reports/                  # Static reports for recruiters/ops
â”‚   â””â”€â”€ weekly_dashboard.pdf
â”‚
â”œâ”€â”€ notebook_init.py          # Auto-path setup for notebooks
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Imports & Constants

Instead of repeating imports and constants across every notebook:

* **Centralize imports**

  ```python
  # config/imports.py
  import pandas as pd
  import numpy as np
  import matplotlib.pyplot as plt
  import seaborn as sns
  import duckdb
  ```

* **Centralize constants**

  ```python
  # config/constants.py
  SLA_TARGET = 0.8  # 80% calls answered within 20s
  SHIFT_HOURS = 8
  BREAKS = [15, 30, 15]  # minutes
  ```

* **Use a helper init**

  ```python
  # notebook_init.py
  import sys, os
  sys.path.append(os.path.abspath(".."))
  ```

  Then in a notebook:

  ```python
  %run ../notebook_init.py
  from config.imports import *
  from config.constants import *
  ```

âœ… Benefits:

* No duplication across notebooks.
* Cleaner, recruiter-friendly notebooks.
* Easier maintenance (one edit updates all).

---

## ğŸ“Š Data Storage & Analysis

### Chosen Options:

* **CSV** â†’ Simple, universally readable, good for sharing raw data.
* **DuckDB** â†’ In-process database, perfect for analytical queries and avoids heavy setup (Postgres).
* **Jupyter + Pandas/Seaborn/Matplotlib** â†’ Core data analysis and visualizations.
* **Metabase** â†’ (Optional) if showcasing SQL-based dashboards.
* **Streamlit** â†’ For live interactive apps (optional, recruiter demo).

---

## ğŸ“‘ Reporting Strategy

We considered **interactive dashboards vs static reports**:

* **Interactive (Metabase/Streamlit)**
  Pros: Recruiters see SQL/BI workflows, ops get interactivity.
  Cons: Requires running environment, less portable.

* **Static (PDF via nbconvert/Quarto)**
  Pros: Recruiter-friendly, easy to email/attach, reproducible.
  Cons: Not interactive.

**Decision:**
ğŸ‘‰ Use **static PDFs for recruiter submissions** (weekly/monthly dashboards).
ğŸ‘‰ Optionally host **interactive dashboards (Streamlit/Metabase)** for bonus points.

---

## ğŸ”„ Workflow Summary

1. **Data Simulation**

   * Generate call arrivals, agent shifts, breaks, emergencies.
   * Store in CSV and DuckDB.

2. **Analysis in Jupyter**

   * Use Pandas for data wrangling.
   * Apply SLA/coverage calculations.
   * Plot KPIs (AHT, ASA, FCR, Occupancy, etc.).

3. **Reporting**

   * Export static dashboards as PDFs.
   * Optionally provide interactive dashboard (Streamlit or Metabase).

4. **Project Organization**

   * Imports and constants centralized.
   * Notebook path setup automated via `notebook_init.py`.

---

## âœ… Key Design Choices & Why

| Decision                           | Reason                                                               |
| ---------------------------------- | -------------------------------------------------------------------- |
| **CSV + DuckDB**                   | Lightweight, recruiter-friendly, supports SQL + Python seamlessly.   |
| **Static PDF reports**             | Recruiters can view instantly; no setup needed.                      |
| **Metabase (optional)**            | Showcases SQL/BI skills with visual dashboards.                      |
| **Streamlit (optional)**           | Demonstrates Python dashboarding, but not mandatory.                 |
| **Imports/constants in `config/`** | Clean, DRY (donâ€™t repeat yourself), professional.                    |
| **`notebook_init.py`**             | Avoids repeating sys.path hacks in every notebook.                   |
| **Project structure**              | Mirrors real-world analytics repos; easy for recruiters to navigate. |

---

## ğŸš€ Next Steps

* Build **baseline data simulation** (calls + agents + shifts).
* Implement **KPI calculations** (SLA, ASA, AHT, occupancy).
* Create **weekly dashboard notebook** â†’ export PDF.
* Add optional **interactive dashboard** (Streamlit or Metabase).
* Polish repo with `README.md`, requirements, and sample outputs.

---

ğŸ‘‰ This doc itself is portfolio material: it shows **structured thinking, documentation skills, and professional workflows**.

---

Would you like me to extend this doc with a **sample KPI table + example visualization workflow** (like SLA chart â†’ PDF) so itâ€™s already â€œportfolio-readyâ€?
